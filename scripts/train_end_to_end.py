#!/usr/bin/env python3
"""
ç«¯åˆ°ç«¯å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æè®­ç»ƒè„šæœ¬
æ”¯æŒç›´æ¥å¤„ç†åŸå§‹æ–‡æœ¬ï¼Œè¿›è¡Œå®Œå…¨ç«¯åˆ°ç«¯è®­ç»ƒ
"""
import os
import sys
import time
import json
import logging
import warnings
from pathlib import Path
from tqdm import tqdm
from typing import Dict, List, Tuple, Any, Optional

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, ReduceLROnPlateau
import numpy as np
from sklearn.metrics import accuracy_score, f1_score

# æŠ‘åˆ¶è­¦å‘Š
warnings.filterwarnings("ignore")

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from src.models.end_to_end_model import EndToEndMultiModalModel
from src.preprocess.end_to_end_dataset import get_end_to_end_dataloaders
from src.training.config import set_seed, load_config, get_device, get_class_weights, create_experiment_dir

# é…ç½®æ—¥å¿—
os.makedirs('logs', exist_ok=True)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('logs/end_to_end_training.log')
    ]
)
logger = logging.getLogger(__name__)


def train_epoch(
    model: nn.Module,
    train_loader: DataLoader,
    optimizer: optim.Optimizer,
    scheduler: Any,
    device: torch.device,
    clip_grad_val: float = 1.0,
    accumulation_steps: int = 1
) -> Dict[str, float]:
    """è®­ç»ƒä¸€ä¸ªepoch"""
    
    model.train()
    
    total_loss = 0.0
    total_samples = 0
    all_preds = []
    all_labels = []
    
    optimizer.zero_grad()  # åˆå§‹åŒ–æ¢¯åº¦
    
    pbar = tqdm(train_loader, desc="Training")
    for batch_idx, batch in enumerate(pbar):
        # è·å–æ•°æ®å¹¶ç§»åŠ¨åˆ°è®¾å¤‡
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        audio_features = batch['audio'].to(device)
        labels = batch['emotion'].to(device)
        
        batch_size = input_ids.size(0)
        
        # å‰å‘ä¼ æ’­
        outputs = model(
            input_ids=input_ids,
            attention_mask=attention_mask,
            audio_features=audio_features,
            return_features=True  # ç”¨äºå¯¹æ¯”æŸå¤±
        )
        
        # è®¡ç®—æŸå¤±
        losses = model.calculate_losses(outputs, labels)
        loss = losses['total_loss'] / accumulation_steps  # æ¢¯åº¦ç´¯ç§¯
        
        # åå‘ä¼ æ’­
        loss.backward()
        
        # æ¢¯åº¦ç´¯ç§¯
        if (batch_idx + 1) % accumulation_steps == 0:
            # æ¢¯åº¦è£å‰ª
            if clip_grad_val > 0:
                torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad_val)
            
            # æ›´æ–°å‚æ•°
            optimizer.step()
            optimizer.zero_grad()
            
            # æ›´æ–°å­¦ä¹ ç‡
            if scheduler is not None and isinstance(scheduler, CosineAnnealingWarmRestarts):
                scheduler.step()
        
        # ç´¯ç§¯æŸå¤±å’Œæ ·æœ¬æ•°
        total_loss += losses['total_loss'].item() * batch_size
        total_samples += batch_size
        
        # é¢„æµ‹ç»“æœ
        preds = torch.argmax(outputs['logits'], dim=1)
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())
        
        # æ›´æ–°è¿›åº¦æ¡
        pbar.set_postfix({
            'Loss': f"{losses['total_loss'].item():.4f}",
            'Avg_Loss': f"{total_loss/total_samples:.4f}"
        })
    
    # å¤„ç†æœ€åçš„æ¢¯åº¦ç´¯ç§¯
    if (len(train_loader) % accumulation_steps) != 0:
        if clip_grad_val > 0:
            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad_val)
        optimizer.step()
        optimizer.zero_grad()
    
    # è®¡ç®—æŒ‡æ ‡
    accuracy = accuracy_score(all_labels, all_preds)
    avg_loss = total_loss / total_samples
    
    return {
        'loss': avg_loss,
        'accuracy': accuracy
    }


def evaluate(
    model: nn.Module,
    data_loader: DataLoader,
    device: torch.device
) -> Dict[str, float]:
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    model.eval()
    
    total_loss = 0.0
    total_samples = 0
    all_preds = []
    all_labels = []
    all_logits = []
    
    with torch.no_grad():
        for batch in tqdm(data_loader, desc="Evaluating"):
            # è·å–æ•°æ®å¹¶ç§»åŠ¨åˆ°è®¾å¤‡
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            audio_features = batch['audio'].to(device)
            labels = batch['emotion'].to(device)
            
            batch_size = input_ids.size(0)
            
            # å‰å‘ä¼ æ’­
            outputs = model(
                input_ids=input_ids,
                attention_mask=attention_mask,
                audio_features=audio_features,
                return_features=True
            )
            
            # è®¡ç®—æŸå¤±
            losses = model.calculate_losses(outputs, labels)
            loss = losses['total_loss']
            
            # ç´¯ç§¯æŸå¤±å’Œæ ·æœ¬æ•°
            total_loss += loss.item() * batch_size
            total_samples += batch_size
            
            # ä¿å­˜logitså’Œæ ‡ç­¾
            all_logits.append(outputs['logits'].cpu())
            all_labels.extend(labels.cpu().numpy())
    
    # åˆå¹¶æ‰€æœ‰logits
    all_logits = torch.cat(all_logits, dim=0)
    all_preds = torch.argmax(all_logits, dim=1).numpy()
    
    # è®¡ç®—æŒ‡æ ‡
    accuracy = accuracy_score(all_labels, all_preds)
    f1_macro = f1_score(all_labels, all_preds, average='macro')
    f1_weighted = f1_score(all_labels, all_preds, average='weighted')
    avg_loss = total_loss / total_samples
    
    return {
        'loss': avg_loss,
        'acc': accuracy,
        'f1_macro': f1_macro,
        'f1_weighted': f1_weighted
    }


def create_optimizers(model, config):
    """åˆ›å»ºä¼˜åŒ–å™¨ï¼Œæ”¯æŒä¸åŒæ¨¡æ€çš„ä¸åŒå­¦ä¹ ç‡"""
    
    training_config = config['training']
    
    # è·å–ä¸åŒçš„å­¦ä¹ ç‡
    base_lr = training_config['lr']
    text_lr = training_config.get('text_lr', base_lr * 0.3)
    audio_lr = training_config.get('audio_lr', base_lr * 0.5)
    
    # åˆ†ç»„å‚æ•°
    text_params = []
    audio_params = []
    other_params = []
    
    for name, param in model.named_parameters():
        if 'text_encoder' in name:
            text_params.append(param)
        elif 'audio_encoder' in name:
            audio_params.append(param)
        else:
            other_params.append(param)
    
    # åˆ›å»ºå‚æ•°ç»„
    param_groups = [
        {'params': text_params, 'lr': text_lr, 'name': 'text'},
        {'params': audio_params, 'lr': audio_lr, 'name': 'audio'},
        {'params': other_params, 'lr': base_lr, 'name': 'other'}
    ]
    
    # è¿‡æ»¤ç©ºç»„
    param_groups = [group for group in param_groups if len(group['params']) > 0]
    
    logger.info(f"ğŸ“Š å‚æ•°ç»„ä¿¡æ¯:")
    for group in param_groups:
        logger.info(f"  - {group['name']}: {len(group['params'])} å‚æ•°, lr={group['lr']:.2e}")
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = optim.AdamW(
        param_groups,
        weight_decay=training_config['weight_decay']
    )
    
    return optimizer


def train_end_to_end_model(config_path: str) -> Tuple[nn.Module, Dict[str, List[float]]]:
    """ç«¯åˆ°ç«¯è®­ç»ƒæ¨¡å‹"""
    
    # åŠ è½½é…ç½®
    config = load_config(config_path)
    
    # è®¾ç½®éšæœºç§å­
    set_seed(config['random_seed'])
    
    # è·å–è®¾å¤‡
    device = get_device()
    logger.info(f"ğŸ”¥ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºå®éªŒç›®å½•
    exp_dir = create_experiment_dir(config)
    logger.info(f"ğŸ“ å®éªŒç›®å½•: {exp_dir}")
    
    # è·å–ç«¯åˆ°ç«¯æ•°æ®åŠ è½½å™¨
    try:
        dataloaders = get_end_to_end_dataloaders(config)
        train_loader = dataloaders['train']
        dev_loader = dataloaders['dev']
        test_loader = dataloaders['test']
        logger.info(f"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åŠ è½½å™¨åˆ›å»ºå¤±è´¥: {e}")
        raise
    
    # åˆ›å»ºç«¯åˆ°ç«¯æ¨¡å‹
    try:
        model = EndToEndMultiModalModel(config)
        model.to(device)
        logger.info(f"âœ… ç«¯åˆ°ç«¯æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # æ‰“å°æ¨¡å‹å‚æ•°ä¿¡æ¯
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        logger.info(f"ğŸ“Š æ¨¡å‹å‚æ•°ç»Ÿè®¡:")
        logger.info(f"  - æ€»å‚æ•°: {total_params:,}")
        logger.info(f"  - å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        logger.info(f"  - å¯è®­ç»ƒæ¯”ä¾‹: {trainable_params/total_params*100:.1f}%")
        
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        raise
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = create_optimizers(model, config)
    
    # åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨
    training_config = config['training']
    num_training_steps = len(train_loader) * training_config['epochs'] // training_config.get('accumulation_steps', 1)
    warmup_steps = int(num_training_steps * training_config['warmup_ratio'])
    
    if training_config.get('scheduler') == 'cosine_with_restarts':
        scheduler = CosineAnnealingWarmRestarts(
            optimizer,
            T_0=warmup_steps,
            T_mult=2
        )
    elif training_config.get('scheduler') == 'plateau':
        scheduler = ReduceLROnPlateau(
            optimizer,
            mode='max',
            factor=0.5,
            patience=3
        )
    else:
        scheduler = None
    
    # åˆå§‹åŒ–è®­ç»ƒå†å²
    history = {
        'train_loss': [],
        'train_acc': [],
        'val_loss': [],
        'val_acc': [],
        'val_f1_macro': [],
        'val_f1_weighted': []
    }
    
    # åˆå§‹åŒ–æœ€ä½³éªŒè¯F1åˆ†æ•°
    best_val_f1 = 0.0
    patience_counter = 0
    early_stopping_patience = training_config.get('early_stopping_patience', 10)
    
    # è®­ç»ƒå¾ªç¯
    logger.info(f"ğŸš€ å¼€å§‹ç«¯åˆ°ç«¯è®­ç»ƒ...")
    for epoch in range(training_config['epochs']):
        logger.info(f"Epoch {epoch+1}/{training_config['epochs']}")
        
        # è®­ç»ƒä¸€ä¸ªepoch
        train_metrics = train_epoch(
            model=model,
            train_loader=train_loader,
            optimizer=optimizer,
            scheduler=scheduler,
            device=device,
            clip_grad_val=training_config['gradient_clip_val'],
            accumulation_steps=training_config.get('accumulation_steps', 1)
        )
        
        # åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
        val_metrics = evaluate(
            model=model,
            data_loader=dev_loader,
            device=device
        )
        
        # æ›´æ–°å­¦ä¹ ç‡ï¼ˆå¦‚æœä½¿ç”¨ReduceLROnPlateauï¼‰
        if scheduler is not None and isinstance(scheduler, ReduceLROnPlateau):
            scheduler.step(val_metrics['f1_weighted'])
        
        # è®°å½•æŒ‡æ ‡
        history['train_loss'].append(train_metrics['loss'])
        history['train_acc'].append(train_metrics['accuracy'])
        history['val_loss'].append(val_metrics['loss'])
        history['val_acc'].append(val_metrics['acc'])
        history['val_f1_macro'].append(val_metrics['f1_macro'])
        history['val_f1_weighted'].append(val_metrics['f1_weighted'])
        
        # æ‰“å°æŒ‡æ ‡
        logger.info(f"Train Loss: {train_metrics['loss']:.4f}, Acc: {train_metrics['accuracy']:.4f}")
        logger.info(f"Val Loss: {val_metrics['loss']:.4f}, Acc: {val_metrics['acc']:.4f}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_metrics['f1_weighted'] > best_val_f1:
            best_val_f1 = val_metrics['f1_weighted']
            patience_counter = 0
            
            # ä¿å­˜æ¨¡å‹
            checkpoint = {
                'epoch': epoch + 1,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'config': config,
                'val_metrics': val_metrics,
                'history': history
            }
            
            best_model_path = os.path.join(exp_dir, 'best_model.pth')
            torch.save(checkpoint, best_model_path)
            
            logger.info(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ŒF1 Weighted: {val_metrics['f1_weighted']:.4f}")
        else:
            patience_counter += 1
        
        # æ—©åœæ£€æŸ¥
        if patience_counter >= early_stopping_patience:
            logger.info(f"â° æ—©åœè§¦å‘ï¼Œæœ€ä½³F1: {best_val_f1:.4f}")
            break
    
    # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æœ€ä½³æ¨¡å‹
    logger.info("ğŸ¯ åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æœ€ä½³æ¨¡å‹...")
    
    # åŠ è½½æœ€ä½³æ¨¡å‹
    best_checkpoint = torch.load(best_model_path, map_location=device, weights_only=False)
    model.load_state_dict(best_checkpoint['model_state_dict'])
    
    # æµ‹è¯•é›†è¯„ä¼°
    test_metrics = evaluate(
        model=model,
        data_loader=test_loader,
        device=device
    )
    
    logger.info(f"ğŸ† æµ‹è¯•é›†æŒ‡æ ‡: Acc: {test_metrics['acc']:.4f}, F1 Macro: {test_metrics['f1_macro']:.4f}, F1 Weighted: {test_metrics['f1_weighted']:.4f}")
    
    # ä¿å­˜è®­ç»ƒå†å²
    history_path = os.path.join(exp_dir, 'history.json')
    with open(history_path, 'w') as f:
        json.dump(history, f, indent=2)
    
    # ä¿å­˜æµ‹è¯•ç»“æœ
    test_results = {
        'test_metrics': test_metrics,
        'best_val_f1': best_val_f1,
        'total_epochs': epoch + 1
    }
    
    results_path = os.path.join(exp_dir, 'test_results.json')
    with open(results_path, 'w') as f:
        json.dump(test_results, f, indent=2)
    
    logger.info(f"âœ… ç«¯åˆ°ç«¯è®­ç»ƒå®Œæˆï¼")
    logger.info(f"ğŸ“Š ç»“æœä¿å­˜åœ¨: {exp_dir}")
    
    return model, history


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ç«¯åˆ°ç«¯å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æè®­ç»ƒ')
    parser.add_argument('--config', type=str, default='configs/config_end_to_end_emotion.json',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    logger.info(f"ğŸ¯ å¼€å§‹ç«¯åˆ°ç«¯è®­ç»ƒ")
    logger.info(f"ğŸ“ é…ç½®æ–‡ä»¶: {args.config}")
    
    try:
        model, history = train_end_to_end_model(args.config)
        logger.info(f"ğŸ‰ è®­ç»ƒæˆåŠŸå®Œæˆï¼")
    except Exception as e:
        logger.error(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main() 