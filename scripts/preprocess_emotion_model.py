#!/usr/bin/env python3
"""
ä¸“é—¨ç”¨äºæƒ…æ„Ÿæ¨¡å‹çš„é¢„å¤„ç†è„šæœ¬
ä½¿ç”¨CardiffNLPçš„twitter-roberta-base-emotionæ¨¡å‹æå–æ–‡æœ¬ç‰¹å¾
"""
import os
import sys
import warnings
import tarfile
from pathlib import Path

# æŠ‘åˆ¶è­¦å‘Šä¿¡æ¯
warnings.filterwarnings("ignore")

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent / 'src'))

from preprocess.text_processor import TextProcessor
from preprocess.audio_processor import AudioProcessor

def check_and_extract_data():
    """æ£€æŸ¥å¹¶è§£å‹MELDæ•°æ®"""
    dataset_path = "data/MELD.Raw"
    tar_path = "data/MELD.Raw.tar.gz"
    
    if os.path.exists(dataset_path):
        print(f"âœ… å‘ç°æ•°æ®ç›®å½•: {dataset_path}")
        return dataset_path
    
    if os.path.exists(tar_path):
        print(f"ğŸ“¦ å‘ç°å‹ç¼©æ–‡ä»¶: {tar_path}")
        print("æ­£åœ¨è§£å‹æ•°æ®...")
        
        with tarfile.open(tar_path, 'r:gz') as tar:
            tar.extractall(path="data/")
        
        print("âœ… æ•°æ®è§£å‹å®Œæˆ")
        return dataset_path
    
    print("âŒ æœªæ‰¾åˆ°MELDæ•°æ®ï¼Œè¯·ç¡®ä¿ data/MELD.Raw.tar.gz æˆ– data/MELD.Raw å­˜åœ¨")
    return None

def main():
    print("ğŸš€ å¼€å§‹ä½¿ç”¨æƒ…æ„Ÿä¸“é—¨æ¨¡å‹æå–ç‰¹å¾...")
    
    # æ£€æŸ¥å’Œå‡†å¤‡æ•°æ®
    dataset_path = check_and_extract_data()
    if not dataset_path:
        print("âŒ æ•°æ®å‡†å¤‡å¤±è´¥ï¼Œé€€å‡º")
        return
    
    # é…ç½®å‚æ•°
    output_dir = "data/processed_emotion"
    emotion_model = "cardiffnlp/twitter-roberta-base-emotion"
    audio_model = "facebook/wav2vec2-base-960h"
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    print(f"\né…ç½®ä¿¡æ¯:")
    print(f"ğŸ“ æ•°æ®é›†è·¯å¾„: {dataset_path}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ¤– æƒ…æ„Ÿæ–‡æœ¬æ¨¡å‹: {emotion_model}")
    print(f"ğŸ¤– éŸ³é¢‘æ¨¡å‹: {audio_model}")
    
    # æ£€æŸ¥å¿…è¦çš„CSVæ–‡ä»¶
    required_files = ["train_sent_emo.csv", "dev_sent_emo.csv", "test_sent_emo.csv"]
    missing_files = []
    for file in required_files:
        if not os.path.exists(os.path.join(dataset_path, file)):
            missing_files.append(file)
    
    if missing_files:
        print(f"âŒ ç¼ºå°‘å¿…è¦æ–‡ä»¶: {missing_files}")
        print("è¯·ç¡®ä¿MELD.Rawç›®å½•åŒ…å«å®Œæ•´çš„CSVæ–‡ä»¶")
        return
    
    # æå–æ–‡æœ¬ç‰¹å¾ï¼ˆä½¿ç”¨æƒ…æ„Ÿä¸“é—¨æ¨¡å‹ï¼‰
    print("\n=== ğŸ”¤ æå–æ–‡æœ¬ç‰¹å¾ï¼ˆæƒ…æ„Ÿä¸“é—¨æ¨¡å‹ï¼‰===")
    try:
        text_processor = TextProcessor(
            model_name=emotion_model,
            use_local=False,  # ç›´æ¥ä»HuggingFaceä¸‹è½½
            device='cuda' if torch.cuda.is_available() else 'cpu'
        )
        
        text_output_dir = os.path.join(output_dir, "text_features")
        text_results = text_processor.process_dataset(dataset_path, text_output_dir)
        print(f"âœ… æ–‡æœ¬ç‰¹å¾æå–å®Œæˆ: {text_results}")
        
    except Exception as e:
        print(f"âŒ æ–‡æœ¬ç‰¹å¾æå–å¤±è´¥: {str(e)}")
        print("å¯èƒ½éœ€è¦å®‰è£…transformers: pip install transformers")
        return
    
    # æå–éŸ³é¢‘ç‰¹å¾ï¼ˆå¤ç”¨åŸæœ‰ç‰¹å¾æˆ–é‡æ–°æå–ï¼‰
    print("\n=== ğŸ”Š å¤„ç†éŸ³é¢‘ç‰¹å¾ ===")
    existing_audio_dir = "data/processed/audio_features"
    if os.path.exists(existing_audio_dir):
        print("å‘ç°å·²æœ‰éŸ³é¢‘ç‰¹å¾ï¼Œå¤åˆ¶åˆ°æ–°ç›®å½•...")
        import shutil
        new_audio_dir = os.path.join(output_dir, "audio_features")
        if os.path.exists(new_audio_dir):
            shutil.rmtree(new_audio_dir)
        shutil.copytree(existing_audio_dir, new_audio_dir)
        print(f"âœ… éŸ³é¢‘ç‰¹å¾å¤åˆ¶å®Œæˆ: {new_audio_dir}")
    else:
        print("âš ï¸  æœªæ‰¾åˆ°å·²æœ‰éŸ³é¢‘ç‰¹å¾")
        print("å¦‚éœ€é‡æ–°æå–éŸ³é¢‘ç‰¹å¾ï¼Œè¯·è¿è¡Œ:")
        print("python src/preprocess/preprocess_all.py --modality audio")
        print("ç°åœ¨è·³è¿‡éŸ³é¢‘ç‰¹å¾...")
        
        # åˆ›å»ºç©ºçš„éŸ³é¢‘ç‰¹å¾ç›®å½•
        audio_output_dir = os.path.join(output_dir, "audio_features")
        os.makedirs(audio_output_dir, exist_ok=True)
    
    print("\nğŸ‰ æƒ…æ„Ÿæ¨¡å‹ç‰¹å¾æå–å®Œæˆ!")
    print(f"ğŸ“ ç‰¹å¾ä¿å­˜ä½ç½®: {output_dir}")
    print(f"ğŸ“‚ æ–‡æœ¬ç‰¹å¾: {os.path.join(output_dir, 'text_features')}")
    print(f"ğŸ“‚ éŸ³é¢‘ç‰¹å¾: {os.path.join(output_dir, 'audio_features')}")
    
    print("\nğŸš€ ä¸‹ä¸€æ­¥: è¿è¡Œè®­ç»ƒå‘½ä»¤")
    print(f"python main.py train --config configs/config_bimodal_emotion.json")

if __name__ == "__main__":
    # å¯¼å…¥torchç”¨äºæ£€æŸ¥CUDA
    try:
        import torch
    except ImportError:
        print("è¯·å®‰è£…PyTorch: pip install torch")
        sys.exit(1)
    
    main() 